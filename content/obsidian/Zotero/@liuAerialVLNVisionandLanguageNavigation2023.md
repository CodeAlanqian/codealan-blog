---


cssclass: research-note
type: conferencePaper
title: 'AerialVLN: Vision-and-Language Navigation for UAVs'
authors: Liu, Shubo; Zhang, Hongsheng; Qi, Yuankai; Wang, Peng; Zhang, Yanning; Wu,
  Qi
publication: ''
date: 2023-10-01
lastmod: 2025-11-26
citekey: liuAerialVLNVisionandLanguageNavigation2023
doi: 10.1109/ICCV51070.2023.01411
url: ''
pdf: file://F:\Zotero_data\storage\BWJFKXVW\Liu%20ç­‰%20-%202023%20-%20AerialVLN%20Vision-and-Language%20Navigation%20for%20UAVs.pdf
tags:
- obscite
- Zotero
- ROS
- VLN
- Ubuntu
- Navigation
---

## ðŸ“˜ Reference Information
**Title:** AerialVLN: Vision-and-Language Navigation for UAVs  
**Authors:** Liu, Shubo; Zhang, Hongsheng; Qi, Yuankai; Wang, Peng; Zhang, Yanning; Wu, Qi  
**Publication:**  (2023)  
**Citekey:** `liuAerialVLNVisionandLanguageNavigation2023`  
**DOI:** [10.1109/ICCV51070.2023.01411](https://doi.org/10.1109/ICCV51070.2023.01411)  
**Links:** [Online](http://zotero.org/users/15485849/items/M9AYZ8FZ) | [PDF](file://F:\Zotero_data\storage\BWJFKXVW\Liu%20ç­‰%20-%202023%20-%20AerialVLN%20Vision-and-Language%20Navigation%20for%20UAVs.pdf)

---

## ðŸ§¾ Metadata
- **Start date:** 2023-10-01
- **End date:** 
- **Page range:** 15384
- **Keywords:** #obscite 

---

## ðŸ§  Abstract / Summary
> ç®€è¦æ¦‚è¿°ç ”ç©¶çš„èƒŒæ™¯ã€ç›®æ ‡ã€æ–¹æ³•ã€ç»“æžœä¸Žç»“è®ºï¼ˆå»ºè®® 3â€“5 å¥ï¼‰ã€‚

---

## ðŸ” Key Concepts
| æ ¸å¿ƒæ¦‚å¿µ | è¯´æ˜Ž |
|-----------|------|
| **Problem** | |
| **Method / Model** | |
| **Result** | |
| **Contribution** | |

---

## ðŸ’¬ Highlights & Annotations
%% begin annotations %%

### Imported on 2025-11-01 10:41 æ™šä¸Š
>[!quote|#5fb236]+ **ðŸ“— Reference**
>   
> [(p. 15384)](zotero://open-pdf/library/items/BWJFKXVW?page=15384&annotation=4TJJN8DT)


> ðŸ’­ *nothing*


---
>[!quote|#ff6666]+ **âš ï¸ Critique**
> Navigating in the sky is more complicated than on the ground because agents need to consider the flying height and more complex spatial relationship reasoning. To fill this gap and facilitate research in this field, we propose a new task named AerialVLN, which is UAV-based and towards outdoor environments.  
> [(p. 15384)](zotero://open-pdf/library/items/BWJFKXVW?page=15384&annotation=LKWETSXX)



---
>[!quote|#a28ae5]+ **ðŸ”§ Method**
> scenarios  
> [(p. 15384)](zotero://open-pdf/library/items/BWJFKXVW?page=15384&annotation=GEXZM4GA)



---
>[!quote|#ffd400]+ **ðŸ“Œ Important**
>   
> [(p. 15384)](zotero://open-pdf/library/items/BWJFKXVW?page=15384&annotation=QZIZFCMJ)


> ðŸ’­ *æ— *


---
>[!quote|#ffd400]+ **ðŸ“Œ Important**
>   
> [(p. 15385)](zotero://open-pdf/library/items/BWJFKXVW?page=15385&annotation=GQBACA7W)



![](/obsidian/Zotero/Zotero/assets/liuAerialVLNVisionandLanguageNavigation2023/image-2-x63-y553.png)

---
>[!quote|#ffd400]+ **ðŸ“Œ Important**
> To release humans from manually operating UAVs and to fill the research gap in the field of navigation in the sky, we propose a city-level UAV-based vision-andlanguage navigation task, named AerialVLN, and a corresponding dataset.  
> [(p. 15385)](zotero://open-pdf/library/items/BWJFKXVW?page=15385&annotation=MA5WBGRP)



---
>[!quote|#5fb236]+ **ðŸ“— Reference**
> On average, up to 83 words are in each instruction, involving a large vocabulary of 4,470 words. Finally, we evaluate five baselines, including two golden standard VLN models in VLN, Seq2Seq model and cross-modal matching (CMA) model, and our proposed model to serve as starting baselines on AerialVLN.  
> [(p. 15385)](zotero://open-pdf/library/items/BWJFKXVW?page=15385&annotation=BA64SYDP)



---
>[!quote|#5fb236]+ **ðŸ“— Reference**
> In this section, we review two types of closely related work: UAV navigation and Ground-based VLN.  
> [(p. 15385)](zotero://open-pdf/library/items/BWJFKXVW?page=15385&annotation=ICLKE8KQ)



---
>[!quote|#ffd400]+ **ðŸ“Œ Important**
>   
> [(p. 15386)](zotero://open-pdf/library/items/BWJFKXVW?page=15386&annotation=IAIFBHYK)



![](/obsidian/Zotero/Zotero/assets/liuAerialVLNVisionandLanguageNavigation2023/image-3-x55-y631.png)

--- %% end annotations %%

---

## ðŸ§© Reflections / Insights
- è¿™ç¯‡æ–‡çŒ®çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ä»€ä¹ˆï¼Ÿ  
- ä¸Žå·²æœ‰ç ”ç©¶ç›¸æ¯”ï¼Œå®ƒçš„ä¸»è¦æ”¹è¿›ç‚¹åœ¨å“ªï¼Ÿ  
- å¯èƒ½çš„å±€é™æ€§æˆ–æœªæ¥æ–¹å‘ï¼Ÿ  

---

## ðŸ”— Connections
- **Related Works:**  
  - 
- **Relevance to My Research:**  
  - 

---

## ðŸ§¾ Citation
> [1]

S. Liu, H. Zhang, Y. Qi, P. Wang, Y. Zhangå’ŒQ. Wu, ã€ŠAerialVLN: Vision-and-Language Navigation for UAVsã€‹, æ”¶å…¥ _2023 IEEE/CVF International Conference on Computer Vision (ICCV)_, Paris, France: IEEE, 10æœˆ 2023, é¡µ 15338ï½ž15348. doi: [10.1109/ICCV51070.2023.01411](https://doi.org/10.1109/ICCV51070.2023.01411).


%% Import Date: 2025-11-01T22:42:02.266+08:00 %%
