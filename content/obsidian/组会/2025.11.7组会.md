---



title: 2025.11.7组会
date: 2025-11-07
lastmod: 2025-11-26
draft: false
tags:
- 组会
- RL
- LLM
- VLN
- Ubuntu
- Navigation
---

---

本周我系统学习了VLN，核心收获如下：

1. **学习范式**：模仿学习（IL）快速入门但性能有限，强化学习（RL）能超越专家但效率低，两者结合（IL+RL）成为主流。

2. **预训练模型**：通过自监督学习（如MLM、ITM）让模型掌握跨模态理解，典型模型有PREVALENT、AirBert。

3. **LLM融合**：大语言模型为VLN注入推理能力，实现零样本导航、复杂指令理解和交互式规划，代表工作有NavGPT、March in Chat。

4. **Air VLN**：无人机导航面临三维规划、视角多变、Sim2Real鸿沟等新挑战，推动模型从反应式控制转向预测性推理。

5. **关键挑战**：接地问题、幻觉、Sim2Real差距仍是瓶颈，未来需探索世界模型和因果推理。

**演进脉络**：IL/RL → 预训练 → LLM推理 → 三维具身导航（VLA）。


https://zhuanlan.zhihu.com/p/21046265072
---

##  一、本周学习概览

本周系统学习了**视觉语言导航（VLN）** 的核心内容，涵盖：

- **学习范式**：模仿学习（IL）与强化学习（RL）的对比与融合
- **预训练模型**：从通用视觉语言模型到导航专属预训练
- **LLM与VLN融合**：大语言模型如何赋能导航推理与规划
- **Air VLN**：从地面到空中的三维导航挑战与模型演进

---

## 二、学习范式：IL & RL

### 1. **模仿学习（IL）**
- **思想**：模仿专家轨迹，视为监督学习问题
- **优点**：数据高效、快速启动
- **缺点**：分布偏移、累积误差、无法超越专家
- **典型模型**：Seq2Seq（R2R）、Speaker-Follower（数据增强）

### 2. **强化学习（RL）**
- **思想**：通过试错与环境交互，最大化累积奖励
- **优点**：可超越专家、鲁棒性强
- **缺点**：样本效率低、奖励设计困难
- **典型模型**：RCM（引入内在奖励：路径-指令匹配度）

### 3. **混合方法：IL + RL**
- **SFT + RFT**：先模仿学习打基础，再强化学习提升鲁棒性
- **典型模型**：VLN‑R1

---

## 三、视觉语言预训练模型

### 1. **预训练目标**
- 解决数据稀缺与泛化鸿沟
- **自监督任务**：MLM、ITM、SAP、TOM、SPREL 等

### 2. **经典架构**
- **PREVALENT**：首次引入“图像-文本-动作”三元组预训练
- **AirBert**：领域内预训练，使用BnB数据集
- **Recurrent VLN-BERT**：引入时序循环机制

### 3. **高级架构**
- **BEVBERT**：基于鸟瞰图（BEV）的地图预训练，提升空间推理能力

---

## 四、LLM与VLN的融合

### 1. **LLM带来的能力跃迁**
- **推理与规划**：任务分解、思维链（CoT）、思维树（ToT）
- **零样本导航**：利用先验知识泛化到新环境
- **复杂指令理解**：支持组合性、条件性指令
- **交互式导航**：支持对话、主动提问

### 2. **典型模型**
- **NavGPT**：零样本推理引擎，模块化架构
- **March in Chat（MiC）**：事件驱动的动态规划，交互式导航
- **Navid**：基于视频的VLM，端到端解决Sim2Real问题

---

## 五、Air VLN：空中视觉语言导航

### 1. **挑战**
- **三维路径规划与6-DoF控制**
- **空中视角下的语义稀疏性**
- **Sim2Real鸿沟**：物理、视觉、传感器差异

### 2. **典型模型**
- **UAV-VLN**：模块化端到端框架，LLM + 视觉基础模型
- **VLFly**：零样本迁移 + 连续控制输出
- **OpenFly-Agent**：基于OpenVLA，支持多源环境与自动化指令生成

### 3. **生态与基准**
- **AirSim**：高保真无人机仿真平台
- **AerialVLN**：首个城市级无人机VLN基准
- **OpenFly**：自动化数据生成 + 大规模数据集 + 基础模型

---

## 六、关键挑战与未来方向

| 挑战 | 说明 | 应对策略 |
|------|------|-----------|
| **接地问题** | 符号与物理世界的对齐困难 | 检索增强生成（RAG） |
| **幻觉问题** | LLM生成与真实环境不符的计划 | 环境状态约束、因果建模 |
| **Sim2Real Gap** | 仿真策略在现实中失效 | 域随机化、真实数据微调 |
| **缺乏因果世界模型** | LLM仅学习相关性，非因果性 | 探索世界模型（World Models） |

---

##  七、总结与启发

- **VLN演进路径**：从IL → RL → 预训练 → LLM → VLA（视觉-语言-动作）
- **LLM是认知核心**：从“预测”转向“推理”，赋予智能体规划与交互能力
- **Air VLN是前沿方向**：三维、连续、长程导航对模型提出更高要求
- **未来重点**：因果世界模型、端到端VLA、真实世界部署